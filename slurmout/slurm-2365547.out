2021-06-29 14:49:16.473256: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-29 14:49:16.473342: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-06-29 14:49:16.473267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-29 14:49:16.473368: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-06-29 14:52:26.869841: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-29 14:52:26.869902: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-06-29 14:52:26.869936: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Orion-16-20.HPC.MsState.Edu): /proc/driver/nvidia/version does not exist
2021-06-29 14:52:26.869924: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-29 14:52:26.869966: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-06-29 14:52:26.869996: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Orion-16-20.HPC.MsState.Edu): /proc/driver/nvidia/version does not exist
2021-06-29 14:52:26.870401: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-06-29 14:52:26.870457: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
2021-06-29 14:52:27.698957: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-06-29 14:52:27.698960: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-06-29 14:52:27.731033: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400000000 Hz
2021-06-29 14:52:27.731086: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400000000 Hz
starting readin
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
(80, 127, 1)
Normalizing training data
(79, 127, 1)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 64, 64)            512       
_________________________________________________________________
dropout (Dropout)            (None, 64, 64)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 32, 32)            14368     
_________________________________________________________________
conv1d_transpose (Conv1DTran (None, 64, 32)            7200      
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 32)            0         
_________________________________________________________________
conv1d_transpose_1 (Conv1DTr (None, 128, 64)           14400     
_________________________________________________________________
conv1d_transpose_2 (Conv1DTr (None, 128, 1)            449       
_________________________________________________________________
cropping1d (Cropping1D)      (None, 127, 1)            0         
=================================================================
Total params: 36,929
Trainable params: 36,929
Non-trainable params: 0
_________________________________________________________________
(79, 127, 1)
Epoch 1/100
starting readin
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
(80, 127, 1)
Normalizing training data
(79, 127, 1)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 64, 64)            512       
_________________________________________________________________
dropout (Dropout)            (None, 64, 64)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 32, 32)            14368     
_________________________________________________________________
conv1d_transpose (Conv1DTran (None, 64, 32)            7200      
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 32)            0         
_________________________________________________________________
conv1d_transpose_1 (Conv1DTr (None, 128, 64)           14400     
_________________________________________________________________
conv1d_transpose_2 (Conv1DTr (None, 128, 1)            449       
_________________________________________________________________
cropping1d (Cropping1D)      (None, 127, 1)            0         
=================================================================
Total params: 36,929
Trainable params: 36,929
Non-trainable params: 0
_________________________________________________________________
(79, 127, 1)
Epoch 1/100
1/1 [==============================] - ETA: 0s - loss: 1.00471/1 [==============================] - 4s 4s/step - loss: 1.0047 - val_loss: 0.5677
1/1 [==============================] - ETA: 0s - loss: 0.99511/1 [==============================] - 4s 4s/step - loss: 0.9951 - val_loss: 0.7300
Epoch 2/100
Epoch 2/100
1/1 [==============================] - ETA: 0s - loss: 0.57801/1 [==============================] - 0s 37ms/step - loss: 0.5780 - val_loss: 10.0791
1/1 [==============================] - ETA: 0s - loss: 0.74031/1 [==============================] - 0s 40ms/step - loss: 0.7403 - val_loss: 1.3545
Epoch 3/100
Epoch 3/100
1/1 [==============================] - ETA: 0s - loss: 9.96431/1 [==============================] - 0s 37ms/step - loss: 9.9643 - val_loss: 0.6941
1/1 [==============================] - ETA: 0s - loss: 1.36831/1 [==============================] - 0s 37ms/step - loss: 1.3683 - val_loss: 0.8880
Epoch 4/100
Epoch 4/100
1/1 [==============================] - ETA: 0s - loss: 0.76111/1 [==============================] - 0s 35ms/step - loss: 0.7611 - val_loss: 0.6406
1/1 [==============================] - ETA: 0s - loss: 0.88781/1 [==============================] - 0s 37ms/step - loss: 0.8878 - val_loss: 0.7217
Epoch 5/100
Epoch 5/100
1/1 [==============================] - ETA: 0s - loss: 0.64901/1 [==============================] - 0s 36ms/step - loss: 0.6490 - val_loss: 0.7825
1/1 [==============================] - ETA: 0s - loss: 0.72131/1 [==============================] - 0s 36ms/step - loss: 0.7213 - val_loss: 0.6004
Epoch 6/100
Epoch 6/100
1/1 [==============================] - ETA: 0s - loss: 0.78481/1 [==============================] - 0s 35ms/step - loss: 0.7848 - val_loss: 0.8797
1/1 [==============================] - ETA: 0s - loss: 0.61451/1 [==============================] - 0s 36ms/step - loss: 0.6145 - val_loss: 0.5872
Epoch 7/100
Epoch 7/100
1/1 [==============================] - ETA: 0s - loss: 0.60101/1 [==============================] - 0s 36ms/step - loss: 0.6010 - val_loss: 0.5629
1/1 [==============================] - ETA: 0s - loss: 0.87001/1 [==============================] - 0s 53ms/step - loss: 0.8700 - val_loss: 0.9005
Epoch 8/100
Epoch 8/100
1/1 [==============================] - ETA: 0s - loss: 0.56941/1 [==============================] - 0s 36ms/step - loss: 0.5694 - val_loss: 0.5459
1/1 [==============================] - ETA: 0s - loss: 0.89171/1 [==============================] - 0s 35ms/step - loss: 0.8917 - val_loss: 0.8936
Epoch 9/100
Epoch 9/100
1/1 [==============================] - ETA: 0s - loss: 0.55191/1 [==============================] - 0s 36ms/step - loss: 0.5519 - val_loss: 0.4084
1/1 [==============================] - ETA: 0s - loss: 0.88931/1 [==============================] - 0s 35ms/step - loss: 0.8893 - val_loss: 0.8776
Epoch 10/100
Epoch 10/100
1/1 [==============================] - ETA: 0s - loss: 0.41841/1 [==============================] - 0s 35ms/step - loss: 0.4184 - val_loss: 0.3118
1/1 [==============================] - ETA: 0s - loss: 0.87211/1 [==============================] - 0s 35ms/step - loss: 0.8721 - val_loss: 0.8414
Epoch 11/100
Epoch 11/100
1/1 [==============================] - ETA: 0s - loss: 0.33891/1 [==============================] - 0s 36ms/step - loss: 0.3389 - val_loss: 0.0847
1/1 [==============================] - ETA: 0s - loss: 0.83591/1 [==============================] - 0s 35ms/step - loss: 0.8359 - val_loss: 0.7762
Epoch 12/100
1/1 [==============================] - ETA: 0s - loss: 0.10991/1 [==============================] - 0s 36ms/step - loss: 0.1099 - val_loss: 0.5122
Epoch 13/100
1/1 [==============================] - ETA: 0s - loss: 0.56291/1 [==============================] - 0s 36ms/step - loss: 0.5629 - val_loss: 0.1378
Epoch 14/100
1/1 [==============================] - ETA: 0s - loss: 0.16701/1 [==============================] - 0s 36ms/step - loss: 0.1670 - val_loss: 0.1069
Epoch 15/100
1/1 [==============================] - ETA: 0s - loss: 0.12371/1 [==============================] - 0s 36ms/step - loss: 0.1237 - val_loss: 0.1966
Epoch 16/100
1/1 [==============================] - ETA: 0s - loss: 0.21511/1 [==============================] - 0s 36ms/step - loss: 0.2151 - val_loss: 0.2354
Epoch 17/100
1/1 [==============================] - ETA: 0s - loss: 0.24711/1 [==============================] - 0s 36ms/step - loss: 0.2471 - val_loss: 0.2849
Epoch 18/100
1/1 [==============================] - ETA: 0s - loss: 0.29371/1 [==============================] - 0s 35ms/step - loss: 0.2937 - val_loss: 0.2772
Epoch 19/100
1/1 [==============================] - ETA: 0s - loss: 0.28631/1 [==============================] - 0s 36ms/step - loss: 0.2863 - val_loss: 0.2439
Epoch 20/100
1/1 [==============================] - ETA: 0s - loss: 0.25821/1 [==============================] - 0s 36ms/step - loss: 0.2582 - val_loss: 0.2281
Epoch 21/100
1/1 [==============================] - ETA: 0s - loss: 0.23971/1 [==============================] - 0s 36ms/step - loss: 0.2397 - val_loss: 0.1716
(127, 1)
(127, 1)
(1, 127, 1)
Traceback (most recent call last):
  File "/work/noaa/da/svarga/anomDetec/AnomDetecEnsem/AnomDetecTemp.py", line 172, in <module>
    plt.title(paths[i])
NameError: name 'paths' is not defined
(127, 1)
(127, 1)
(1, 127, 1)
Traceback (most recent call last):
  File "/work/noaa/da/svarga/anomDetec/AnomDetecEnsem/AnomDetecTemp.py", line 172, in <module>
    plt.title(paths[i])
NameError: name 'paths' is not defined
srun: error: Orion-16-20: tasks 0-1: Exited with exit code 1
srun: Terminating job step 2365547.0
