2021-06-22 13:23:06.587940: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-22 13:23:06.587970: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-06-22 13:23:06.587961: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-22 13:23:06.588021: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-06-22 13:23:51.762643: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-22 13:23:51.762689: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-06-22 13:23:51.762941: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-22 13:23:51.762989: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-06-22 13:23:51.770736: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Orion-23-02.HPC.MsState.Edu): /proc/driver/nvidia/version does not exist
2021-06-22 13:23:51.770776: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Orion-23-02.HPC.MsState.Edu): /proc/driver/nvidia/version does not exist
2021-06-22 13:23:51.771180: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-06-22 13:23:51.771183: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
2021-06-22 13:23:52.655124: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-06-22 13:23:52.655342: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-06-22 13:23:52.700011: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400000000 Hz
2021-06-22 13:23:52.700210: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400000000 Hz
(40, 100, 2)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 50, 32)            480       
_________________________________________________________________
dropout (Dropout)            (None, 50, 32)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 25, 16)            3600      
_________________________________________________________________
conv1d_transpose (Conv1DTran (None, 50, 16)            1808      
_________________________________________________________________
dropout_1 (Dropout)          (None, 50, 16)            0         
_________________________________________________________________
conv1d_transpose_1 (Conv1DTr (None, 100, 32)           3616      
_________________________________________________________________
conv1d_transpose_2 (Conv1DTr (None, 100, 1)            225       
=================================================================
Total params: 9,729
Trainable params: 9,729
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
(40, 100, 2)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 50, 32)            480       
_________________________________________________________________
dropout (Dropout)            (None, 50, 32)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 25, 16)            3600      
_________________________________________________________________
conv1d_transpose (Conv1DTran (None, 50, 16)            1808      
_________________________________________________________________
dropout_1 (Dropout)          (None, 50, 16)            0         
_________________________________________________________________
conv1d_transpose_1 (Conv1DTr (None, 100, 32)           3616      
_________________________________________________________________
conv1d_transpose_2 (Conv1DTr (None, 100, 1)            225       
=================================================================
Total params: 9,729
Trainable params: 9,729
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
1/1 [==============================] - ETA: 0s - loss: 27.26911/1 [==============================] - 3s 3s/step - loss: 27.2691 - val_loss: 26.1470
1/1 [==============================] - ETA: 0s - loss: 26.73541/1 [==============================] - 3s 3s/step - loss: 26.7354 - val_loss: 25.9906
Epoch 2/50
Epoch 2/50
1/1 [==============================] - ETA: 0s - loss: 25.92941/1 [==============================] - 0s 19ms/step - loss: 25.9294 - val_loss: 25.0213
1/1 [==============================] - ETA: 0s - loss: 26.40941/1 [==============================] - 0s 21ms/step - loss: 26.4094 - val_loss: 25.2007
Epoch 3/50
Epoch 3/50
1/1 [==============================] - ETA: 0s - loss: 24.81161/1 [==============================] - 0s 18ms/step - loss: 24.8116 - val_loss: 23.8536
1/1 [==============================] - ETA: 0s - loss: 25.38591/1 [==============================] - 0s 19ms/step - loss: 25.3859 - val_loss: 24.0882
Epoch 4/50
Epoch 4/50
1/1 [==============================] - ETA: 0s - loss: 23.51581/1 [==============================] - 0s 17ms/step - loss: 23.5158 - val_loss: 22.4257
1/1 [==============================] - ETA: 0s - loss: 24.24191/1 [==============================] - 0s 18ms/step - loss: 24.2419 - val_loss: 22.7813
Epoch 5/50
Epoch 5/50
1/1 [==============================] - ETA: 0s - loss: 22.02131/1 [==============================] - 0s 17ms/step - loss: 22.0213 - val_loss: 20.7854
1/1 [==============================] - ETA: 0s - loss: 22.80471/1 [==============================] - 0s 18ms/step - loss: 22.8047 - val_loss: 21.3179
Epoch 6/50
Epoch 6/50
1/1 [==============================] - ETA: 0s - loss: 20.37211/1 [==============================] - 0s 17ms/step - loss: 20.3721 - val_loss: 18.9253
Epoch 7/50
1/1 [==============================] - ETA: 0s - loss: 21.47441/1 [==============================] - 0s 18ms/step - loss: 21.4744 - val_loss: 19.7588
Epoch 7/50
1/1 [==============================] - ETA: 0s - loss: 18.63391/1 [==============================] - 0s 17ms/step - loss: 18.6339 - val_loss: 17.1014
Epoch 8/50
1/1 [==============================] - ETA: 0s - loss: 19.74441/1 [==============================] - 0s 18ms/step - loss: 19.7444 - val_loss: 18.1911
Epoch 8/50
1/1 [==============================] - ETA: 0s - loss: 16.97731/1 [==============================] - 0s 16ms/step - loss: 16.9773 - val_loss: 15.7091
Epoch 9/50
1/1 [==============================] - ETA: 0s - loss: 18.23861/1 [==============================] - 0s 18ms/step - loss: 18.2386 - val_loss: 16.7735
1/1 [==============================] - ETA: 0s - loss: 15.89021/1 [==============================] - 0s 16ms/step - loss: 15.8902 - val_loss: 15.3188
Epoch 9/50
Epoch 10/50
1/1 [==============================] - ETA: 0s - loss: 16.99571/1 [==============================] - 0s 18ms/step - loss: 16.9957 - val_loss: 15.7526
1/1 [==============================] - ETA: 0s - loss: 15.86581/1 [==============================] - 0s 16ms/step - loss: 15.8658 - val_loss: 16.0128
Epoch 10/50
Epoch 11/50
1/1 [==============================] - ETA: 0s - loss: 16.06611/1 [==============================] - 0s 18ms/step - loss: 16.0661 - val_loss: 15.4256
1/1 [==============================] - ETA: 0s - loss: 16.82561/1 [==============================] - 0s 16ms/step - loss: 16.8256 - val_loss: 16.5165
Epoch 11/50
Epoch 12/50
1/1 [==============================] - ETA: 0s - loss: 15.98811/1 [==============================] - 0s 18ms/step - loss: 15.9881 - val_loss: 15.8460
1/1 [==============================] - ETA: 0s - loss: 17.61481/1 [==============================] - 0s 16ms/step - loss: 17.6148 - val_loss: 16.2475
Epoch 12/50
Epoch 13/50
1/1 [==============================] - ETA: 0s - loss: 17.17731/1 [==============================] - 0s 16ms/step - loss: 17.1773 - val_loss: 15.6681
1/1 [==============================] - ETA: 0s - loss: 16.69731/1 [==============================] - 0s 18ms/step - loss: 16.6973 - val_loss: 16.3631
Epoch 14/50
Epoch 13/50
1/1 [==============================] - ETA: 0s - loss: 16.33471/1 [==============================] - 0s 17ms/step - loss: 16.3347 - val_loss: 15.2230
1/1 [==============================] - ETA: 0s - loss: 17.30321/1 [==============================] - 0s 18ms/step - loss: 17.3032 - val_loss: 16.4086
Epoch 15/50
Epoch 14/50
1/1 [==============================] - ETA: 0s - loss: 15.83111/1 [==============================] - 0s 17ms/step - loss: 15.8311 - val_loss: 15.0729
1/1 [==============================] - ETA: 0s - loss: 17.64081/1 [==============================] - 0s 18ms/step - loss: 17.6408 - val_loss: 16.0190
Epoch 16/50
Epoch 15/50
1/1 [==============================] - ETA: 0s - loss: 15.51391/1 [==============================] - 0s 16ms/step - loss: 15.5139 - val_loss: 15.1843
1/1 [==============================] - ETA: 0s - loss: 17.09731/1 [==============================] - 0s 18ms/step - loss: 17.0973 - val_loss: 15.5341
Epoch 17/50
1/1 [==============================] - ETA: 0s - loss: 15.39621/1 [==============================] - 0s 16ms/step - loss: 15.3962 - val_loss: 15.4297
Epoch 18/50
1/1 [==============================] - ETA: 0s - loss: 15.49871/1 [==============================] - 0s 17ms/step - loss: 15.4987 - val_loss: 15.6907
Epoch 19/50
1/1 [==============================] - ETA: 0s - loss: 15.68491/1 [==============================] - 0s 17ms/step - loss: 15.6849 - val_loss: 15.8885
Epoch 20/50
1/1 [==============================] - ETA: 0s - loss: 15.86941/1 [==============================] - 0s 17ms/step - loss: 15.8694 - val_loss: 15.9851
(100, 2)
(100, 1)
(100, 2)
(100, 1)
