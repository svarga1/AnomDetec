2021-06-29 14:57:13.448633: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-29 14:57:13.448660: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-06-29 14:57:13.448627: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-29 14:57:13.448663: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-06-29 15:00:44.262750: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-29 15:00:44.262756: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-29 15:00:44.262809: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-06-29 15:00:44.262816: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-06-29 15:00:44.262837: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Orion-04-01.HPC.MsState.Edu): /proc/driver/nvidia/version does not exist
2021-06-29 15:00:44.262846: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Orion-04-01.HPC.MsState.Edu): /proc/driver/nvidia/version does not exist
2021-06-29 15:00:44.263224: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-06-29 15:00:44.263274: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
2021-06-29 15:00:47.830154: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-06-29 15:00:47.830286: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-06-29 15:00:47.945845: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400000000 Hz
2021-06-29 15:00:47.946003: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400000000 Hz
starting readin
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
(80, 127, 1)
Normalizing training data
(79, 127, 1)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 64, 64)            512       
_________________________________________________________________
dropout (Dropout)            (None, 64, 64)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 32, 32)            14368     
_________________________________________________________________
conv1d_transpose (Conv1DTran (None, 64, 32)            7200      
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 32)            0         
_________________________________________________________________
conv1d_transpose_1 (Conv1DTr (None, 128, 64)           14400     
_________________________________________________________________
conv1d_transpose_2 (Conv1DTr (None, 128, 1)            449       
_________________________________________________________________
cropping1d (Cropping1D)      (None, 127, 1)            0         
=================================================================
Total params: 36,929
Trainable params: 36,929
Non-trainable params: 0
_________________________________________________________________
(79, 127, 1)
Epoch 1/100
starting readin
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
(80, 127, 1)
Normalizing training data
(79, 127, 1)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 64, 64)            512       
_________________________________________________________________
dropout (Dropout)            (None, 64, 64)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 32, 32)            14368     
_________________________________________________________________
conv1d_transpose (Conv1DTran (None, 64, 32)            7200      
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 32)            0         
_________________________________________________________________
conv1d_transpose_1 (Conv1DTr (None, 128, 64)           14400     
_________________________________________________________________
conv1d_transpose_2 (Conv1DTr (None, 128, 1)            449       
_________________________________________________________________
cropping1d (Cropping1D)      (None, 127, 1)            0         
=================================================================
Total params: 36,929
Trainable params: 36,929
Non-trainable params: 0
_________________________________________________________________
(79, 127, 1)
Epoch 1/100
1/1 [==============================] - ETA: 0s - loss: 1.00141/1 [==============================] - 10s 10s/step - loss: 1.0014 - val_loss: 0.6345
1/1 [==============================] - ETA: 0s - loss: 0.99681/1 [==============================] - 10s 10s/step - loss: 0.9968 - val_loss: 0.6539
Epoch 2/100
Epoch 2/100
1/1 [==============================] - ETA: 0s - loss: 0.65241/1 [==============================] - 0s 40ms/step - loss: 0.6524 - val_loss: 2.8642
1/1 [==============================] - ETA: 0s - loss: 0.66651/1 [==============================] - 0s 41ms/step - loss: 0.6665 - val_loss: 1.0555
Epoch 3/100
Epoch 3/100
1/1 [==============================] - ETA: 0s - loss: 2.90021/1 [==============================] - 0s 36ms/step - loss: 2.9002 - val_loss: 1.0917
1/1 [==============================] - ETA: 0s - loss: 1.03051/1 [==============================] - 0s 38ms/step - loss: 1.0305 - val_loss: 1.3896
Epoch 4/100
Epoch 4/100
1/1 [==============================] - ETA: 0s - loss: 1.11841/1 [==============================] - 0s 37ms/step - loss: 1.1184 - val_loss: 0.4836
1/1 [==============================] - ETA: 0s - loss: 1.42681/1 [==============================] - 0s 37ms/step - loss: 1.4268 - val_loss: 0.6569
Epoch 5/100
Epoch 5/100
1/1 [==============================] - ETA: 0s - loss: 0.49641/1 [==============================] - 0s 36ms/step - loss: 0.4964 - val_loss: 0.7331
1/1 [==============================] - ETA: 0s - loss: 0.67271/1 [==============================] - 0s 37ms/step - loss: 0.6727 - val_loss: 0.6501
Epoch 6/100
Epoch 6/100
1/1 [==============================] - ETA: 0s - loss: 0.73231/1 [==============================] - 0s 37ms/step - loss: 0.7323 - val_loss: 0.8605
1/1 [==============================] - ETA: 0s - loss: 0.65081/1 [==============================] - 0s 37ms/step - loss: 0.6508 - val_loss: 0.6247
Epoch 7/100
Epoch 7/100
1/1 [==============================] - ETA: 0s - loss: 0.86001/1 [==============================] - 0s 36ms/step - loss: 0.8600 - val_loss: 0.9168
1/1 [==============================] - ETA: 0s - loss: 0.62441/1 [==============================] - 0s 37ms/step - loss: 0.6244 - val_loss: 0.5573
Epoch 8/100
Epoch 8/100
1/1 [==============================] - ETA: 0s - loss: 0.91261/1 [==============================] - 0s 36ms/step - loss: 0.9126 - val_loss: 0.9393
1/1 [==============================] - ETA: 0s - loss: 0.55881/1 [==============================] - 0s 37ms/step - loss: 0.5588 - val_loss: 0.5524
Epoch 9/100
Epoch 9/100
1/1 [==============================] - ETA: 0s - loss: 0.93511/1 [==============================] - 0s 36ms/step - loss: 0.9351 - val_loss: 0.9459
1/1 [==============================] - ETA: 0s - loss: 0.55941/1 [==============================] - 0s 37ms/step - loss: 0.5594 - val_loss: 0.5226
Epoch 10/100
Epoch 10/100
1/1 [==============================] - ETA: 0s - loss: 0.94311/1 [==============================] - 0s 36ms/step - loss: 0.9431 - val_loss: 0.9452
1/1 [==============================] - ETA: 0s - loss: 0.52771/1 [==============================] - 0s 36ms/step - loss: 0.5277 - val_loss: 0.4791
Epoch 11/100
Epoch 11/100
1/1 [==============================] - ETA: 0s - loss: 0.94221/1 [==============================] - 0s 36ms/step - loss: 0.9422 - val_loss: 0.9394
1/1 [==============================] - ETA: 0s - loss: 0.48271/1 [==============================] - 0s 37ms/step - loss: 0.4827 - val_loss: 0.4633
Epoch 12/100
Epoch 12/100
1/1 [==============================] - ETA: 0s - loss: 0.93601/1 [==============================] - 0s 37ms/step - loss: 0.9360 - val_loss: 0.9264
1/1 [==============================] - ETA: 0s - loss: 0.46571/1 [==============================] - 0s 37ms/step - loss: 0.4657 - val_loss: 0.3958
Epoch 13/100
Epoch 13/100
1/1 [==============================] - ETA: 0s - loss: 0.92391/1 [==============================] - 0s 36ms/step - loss: 0.9239 - val_loss: 0.9038
1/1 [==============================] - ETA: 0s - loss: 0.40381/1 [==============================] - 0s 37ms/step - loss: 0.4038 - val_loss: 0.3026
Epoch 14/100
Epoch 14/100
1/1 [==============================] - ETA: 0s - loss: 0.90021/1 [==============================] - 0s 36ms/step - loss: 0.9002 - val_loss: 0.8647
1/1 [==============================] - ETA: 0s - loss: 0.31131/1 [==============================] - 0s 37ms/step - loss: 0.3113 - val_loss: 0.2167
Epoch 15/100
1/1 [==============================] - ETA: 0s - loss: 0.23341/1 [==============================] - 0s 37ms/step - loss: 0.2334 - val_loss: 0.1082
Epoch 16/100
1/1 [==============================] - ETA: 0s - loss: 0.12411/1 [==============================] - 0s 37ms/step - loss: 0.1241 - val_loss: 0.0955
Epoch 17/100
1/1 [==============================] - ETA: 0s - loss: 0.11661/1 [==============================] - 0s 37ms/step - loss: 0.1166 - val_loss: 0.2066
Epoch 18/100
1/1 [==============================] - ETA: 0s - loss: 0.24761/1 [==============================] - 0s 36ms/step - loss: 0.2476 - val_loss: 0.1478
Epoch 19/100
1/1 [==============================] - ETA: 0s - loss: 0.18241/1 [==============================] - 0s 37ms/step - loss: 0.1824 - val_loss: 0.0696
Epoch 20/100
1/1 [==============================] - ETA: 0s - loss: 0.09411/1 [==============================] - 0s 37ms/step - loss: 0.0941 - val_loss: 0.0583
Epoch 21/100
1/1 [==============================] - ETA: 0s - loss: 0.07851/1 [==============================] - 0s 37ms/step - loss: 0.0785 - val_loss: 0.0755
Epoch 22/100
1/1 [==============================] - ETA: 0s - loss: 0.08731/1 [==============================] - 0s 37ms/step - loss: 0.0873 - val_loss: 0.0953
Epoch 23/100
1/1 [==============================] - ETA: 0s - loss: 0.10331/1 [==============================] - 0s 37ms/step - loss: 0.1033 - val_loss: 0.0776
Epoch 24/100
1/1 [==============================] - ETA: 0s - loss: 0.08751/1 [==============================] - 0s 37ms/step - loss: 0.0875 - val_loss: 0.0531
Epoch 25/100
1/1 [==============================] - ETA: 0s - loss: 0.06981/1 [==============================] - 0s 37ms/step - loss: 0.0698 - val_loss: 0.0229
Epoch 26/100
1/1 [==============================] - ETA: 0s - loss: 0.04141/1 [==============================] - 0s 36ms/step - loss: 0.0414 - val_loss: 0.0213
Epoch 27/100
1/1 [==============================] - ETA: 0s - loss: 0.04511/1 [==============================] - 0s 37ms/step - loss: 0.0451 - val_loss: 0.0321
Epoch 28/100
1/1 [==============================] - ETA: 0s - loss: 0.05461/1 [==============================] - 0s 38ms/step - loss: 0.0546 - val_loss: 0.0231
Epoch 29/100
1/1 [==============================] - ETA: 0s - loss: 0.05101/1 [==============================] - 0s 38ms/step - loss: 0.0510 - val_loss: 0.0115
Epoch 30/100
1/1 [==============================] - ETA: 0s - loss: 0.03601/1 [==============================] - 0s 39ms/step - loss: 0.0360 - val_loss: 0.0185
Epoch 31/100
1/1 [==============================] - ETA: 0s - loss: 0.03691/1 [==============================] - 0s 37ms/step - loss: 0.0369 - val_loss: 0.0246
Epoch 32/100
1/1 [==============================] - ETA: 0s - loss: 0.03981/1 [==============================] - 0s 37ms/step - loss: 0.0398 - val_loss: 0.0242
Epoch 33/100
1/1 [==============================] - ETA: 0s - loss: 0.04311/1 [==============================] - 0s 37ms/step - loss: 0.0431 - val_loss: 0.0176
Epoch 34/100
1/1 [==============================] - ETA: 0s - loss: 0.03571/1 [==============================] - 0s 38ms/step - loss: 0.0357 - val_loss: 0.0095
Epoch 35/100
1/1 [==============================] - ETA: 0s - loss: 0.02811/1 [==============================] - 0s 37ms/step - loss: 0.0281 - val_loss: 0.0063
Epoch 36/100
1/1 [==============================] - ETA: 0s - loss: 0.02721/1 [==============================] - 0s 37ms/step - loss: 0.0272 - val_loss: 0.0078
Epoch 37/100
1/1 [==============================] - ETA: 0s - loss: 0.02971/1 [==============================] - 0s 37ms/step - loss: 0.0297 - val_loss: 0.0097
Epoch 38/100
1/1 [==============================] - ETA: 0s - loss: 0.03251/1 [==============================] - 0s 37ms/step - loss: 0.0325 - val_loss: 0.0074
Epoch 39/100
1/1 [==============================] - ETA: 0s - loss: 0.02591/1 [==============================] - 0s 37ms/step - loss: 0.0259 - val_loss: 0.0084
Epoch 40/100
1/1 [==============================] - ETA: 0s - loss: 0.02321/1 [==============================] - 0s 37ms/step - loss: 0.0232 - val_loss: 0.0075
Epoch 41/100
1/1 [==============================] - ETA: 0s - loss: 0.02151/1 [==============================] - 0s 39ms/step - loss: 0.0215 - val_loss: 0.0109
(127, 1)
(127, 1)
(1, 127, 1)
101
(1, 127, 1)
Traceback (most recent call last):
  File "/work/noaa/da/svarga/anomDetec/AnomDetecEnsem/AnomDetecTemp.py", line 205, in <module>
    plt.plot(x_test[anomalies],pres[anomalies], color='r')
  File "/apps/python-3.9.2/lib/python3.9/site-packages/numpy/ma/core.py", line 3219, in __getitem__
    dout = self.data[indx]
IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed
Epoch 42/100
1/1 [==============================] - ETA: 0s - loss: 0.02681/1 [==============================] - 0s 37ms/step - loss: 0.0268 - val_loss: 0.0097
Epoch 43/100
1/1 [==============================] - ETA: 0s - loss: 0.02321/1 [==============================] - 0s 37ms/step - loss: 0.0232 - val_loss: 0.0091
Epoch 44/100
1/1 [==============================] - ETA: 0s - loss: 0.02291/1 [==============================] - 0s 37ms/step - loss: 0.0229 - val_loss: 0.0031
Epoch 45/100
1/1 [==============================] - ETA: 0s - loss: 0.01861/1 [==============================] - 0s 38ms/step - loss: 0.0186 - val_loss: 0.0038
Epoch 46/100
1/1 [==============================] - ETA: 0s - loss: 0.02161/1 [==============================] - 0s 36ms/step - loss: 0.0216 - val_loss: 0.0036
Epoch 47/100
1/1 [==============================] - ETA: 0s - loss: 0.02141/1 [==============================] - 0s 38ms/step - loss: 0.0214 - val_loss: 0.0037
Epoch 48/100
1/1 [==============================] - ETA: 0s - loss: 0.01891/1 [==============================] - 0s 37ms/step - loss: 0.0189 - val_loss: 0.0026
Epoch 49/100
1/1 [==============================] - ETA: 0s - loss: 0.01721/1 [==============================] - 0s 37ms/step - loss: 0.0172 - val_loss: 0.0045
Epoch 50/100
1/1 [==============================] - ETA: 0s - loss: 0.01891/1 [==============================] - 0s 38ms/step - loss: 0.0189 - val_loss: 0.0053
Epoch 51/100
1/1 [==============================] - ETA: 0s - loss: 0.01781/1 [==============================] - 0s 37ms/step - loss: 0.0178 - val_loss: 0.0064
Epoch 52/100
1/1 [==============================] - ETA: 0s - loss: 0.01701/1 [==============================] - 0s 40ms/step - loss: 0.0170 - val_loss: 0.0032
Epoch 53/100
1/1 [==============================] - ETA: 0s - loss: 0.01811/1 [==============================] - 0s 38ms/step - loss: 0.0181 - val_loss: 0.0019
Epoch 54/100
1/1 [==============================] - ETA: 0s - loss: 0.01861/1 [==============================] - 0s 37ms/step - loss: 0.0186 - val_loss: 0.0019
Epoch 55/100
1/1 [==============================] - ETA: 0s - loss: 0.01741/1 [==============================] - 0s 38ms/step - loss: 0.0174 - val_loss: 0.0025
Epoch 56/100
1/1 [==============================] - ETA: 0s - loss: 0.01621/1 [==============================] - 0s 37ms/step - loss: 0.0162 - val_loss: 0.0023
Epoch 57/100
1/1 [==============================] - ETA: 0s - loss: 0.01561/1 [==============================] - 0s 37ms/step - loss: 0.0156 - val_loss: 0.0028
Epoch 58/100
1/1 [==============================] - ETA: 0s - loss: 0.01491/1 [==============================] - 0s 38ms/step - loss: 0.0149 - val_loss: 0.0039
Epoch 59/100
1/1 [==============================] - ETA: 0s - loss: 0.01591/1 [==============================] - 0s 37ms/step - loss: 0.0159 - val_loss: 0.0056
Epoch 60/100
1/1 [==============================] - ETA: 0s - loss: 0.01531/1 [==============================] - 0s 37ms/step - loss: 0.0153 - val_loss: 0.0031
Epoch 61/100
1/1 [==============================] - ETA: 0s - loss: 0.01561/1 [==============================] - 0s 37ms/step - loss: 0.0156 - val_loss: 0.0019
Epoch 62/100
1/1 [==============================] - ETA: 0s - loss: 0.01421/1 [==============================] - 0s 37ms/step - loss: 0.0142 - val_loss: 0.0017
Epoch 63/100
1/1 [==============================] - ETA: 0s - loss: 0.01501/1 [==============================] - 0s 37ms/step - loss: 0.0150 - val_loss: 0.0036
Epoch 64/100
1/1 [==============================] - ETA: 0s - loss: 0.01531/1 [==============================] - 0s 37ms/step - loss: 0.0153 - val_loss: 0.0015
Epoch 65/100
1/1 [==============================] - ETA: 0s - loss: 0.01371/1 [==============================] - 0s 37ms/step - loss: 0.0137 - val_loss: 0.0021
Epoch 66/100
1/1 [==============================] - ETA: 0s - loss: 0.01571/1 [==============================] - 0s 37ms/step - loss: 0.0157 - val_loss: 0.0049
Epoch 67/100
1/1 [==============================] - ETA: 0s - loss: 0.01401/1 [==============================] - 0s 37ms/step - loss: 0.0140 - val_loss: 0.0054
Epoch 68/100
1/1 [==============================] - ETA: 0s - loss: 0.01481/1 [==============================] - 0s 36ms/step - loss: 0.0148 - val_loss: 0.0022
Epoch 69/100
1/1 [==============================] - ETA: 0s - loss: 0.01501/1 [==============================] - 0s 37ms/step - loss: 0.0150 - val_loss: 0.0011
Epoch 70/100
1/1 [==============================] - ETA: 0s - loss: 0.01301/1 [==============================] - 0s 37ms/step - loss: 0.0130 - val_loss: 0.0064
Epoch 71/100
1/1 [==============================] - ETA: 0s - loss: 0.01571/1 [==============================] - 0s 38ms/step - loss: 0.0157 - val_loss: 0.0020
Epoch 72/100
1/1 [==============================] - ETA: 0s - loss: 0.01281/1 [==============================] - 0s 37ms/step - loss: 0.0128 - val_loss: 0.0022
Epoch 73/100
1/1 [==============================] - ETA: 0s - loss: 0.01541/1 [==============================] - 0s 37ms/step - loss: 0.0154 - val_loss: 0.0023
Epoch 74/100
1/1 [==============================] - ETA: 0s - loss: 0.01151/1 [==============================] - 0s 37ms/step - loss: 0.0115 - val_loss: 0.0064
Epoch 75/100
1/1 [==============================] - ETA: 0s - loss: 0.01431/1 [==============================] - 0s 38ms/step - loss: 0.0143 - val_loss: 0.0017
Epoch 76/100
1/1 [==============================] - ETA: 0s - loss: 0.01231/1 [==============================] - 0s 37ms/step - loss: 0.0123 - val_loss: 0.0011
Epoch 77/100
1/1 [==============================] - ETA: 0s - loss: 0.01241/1 [==============================] - 0s 37ms/step - loss: 0.0124 - val_loss: 0.0029
Epoch 78/100
1/1 [==============================] - ETA: 0s - loss: 0.01381/1 [==============================] - 0s 37ms/step - loss: 0.0138 - val_loss: 0.0024
Epoch 79/100
1/1 [==============================] - ETA: 0s - loss: 0.01131/1 [==============================] - 0s 37ms/step - loss: 0.0113 - val_loss: 0.0013
Epoch 80/100
1/1 [==============================] - ETA: 0s - loss: 0.01171/1 [==============================] - 0s 36ms/step - loss: 0.0117 - val_loss: 0.0015
Epoch 81/100
1/1 [==============================] - ETA: 0s - loss: 0.01161/1 [==============================] - 0s 37ms/step - loss: 0.0116 - val_loss: 0.0032
Epoch 82/100
1/1 [==============================] - ETA: 0s - loss: 0.01111/1 [==============================] - 0s 36ms/step - loss: 0.0111 - val_loss: 0.0039
Epoch 83/100
1/1 [==============================] - ETA: 0s - loss: 0.01031/1 [==============================] - 0s 38ms/step - loss: 0.0103 - val_loss: 0.0012
Epoch 84/100
1/1 [==============================] - ETA: 0s - loss: 0.01071/1 [==============================] - 0s 37ms/step - loss: 0.0107 - val_loss: 0.0011
Epoch 85/100
1/1 [==============================] - ETA: 0s - loss: 0.01071/1 [==============================] - 0s 38ms/step - loss: 0.0107 - val_loss: 0.0027
Epoch 86/100
1/1 [==============================] - ETA: 0s - loss: 0.01151/1 [==============================] - 0s 37ms/step - loss: 0.0115 - val_loss: 0.0016
(127, 1)
(127, 1)
(1, 127, 1)
83
(1, 127, 1)
Traceback (most recent call last):
  File "/work/noaa/da/svarga/anomDetec/AnomDetecEnsem/AnomDetecTemp.py", line 205, in <module>
    plt.plot(x_test[anomalies],pres[anomalies], color='r')
  File "/apps/python-3.9.2/lib/python3.9/site-packages/numpy/ma/core.py", line 3219, in __getitem__
    dout = self.data[indx]
IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed
srun: error: Orion-04-01: tasks 0-1: Exited with exit code 1
srun: Terminating job step 2365633.0
