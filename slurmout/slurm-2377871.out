2021-06-30 14:47:06.318998: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-30 14:47:06.319094: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-06-30 14:47:06.319051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-30 14:47:06.319136: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-06-30 14:48:11.529580: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-30 14:48:11.529920: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/python-3.9.2/lib:/lib64:/usr/lib64:/lib:/usr/lib:/usr/lib64/qt-3.3/lib:/opt/slurm/lib:/opt/slurm/lib/slurm
2021-06-30 14:48:11.551680: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-06-30 14:48:11.551683: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-06-30 14:48:11.554163: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Orion-18-03.HPC.MsState.Edu): /proc/driver/nvidia/version does not exist
2021-06-30 14:48:11.554165: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Orion-18-03.HPC.MsState.Edu): /proc/driver/nvidia/version does not exist
2021-06-30 14:48:11.554604: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-06-30 14:48:11.554611: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
2021-06-30 14:48:12.794066: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-06-30 14:48:12.794100: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-06-30 14:48:12.859063: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400000000 Hz
2021-06-30 14:48:12.859313: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400000000 Hz
starting readin
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
(80, 127, 1)
Normalizing training data
(79, 127, 1)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 64, 64)            512       
_________________________________________________________________
dropout (Dropout)            (None, 64, 64)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 32, 32)            14368     
_________________________________________________________________
conv1d_transpose (Conv1DTran (None, 64, 32)            7200      
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 32)            0         
_________________________________________________________________
conv1d_transpose_1 (Conv1DTr (None, 128, 64)           14400     
_________________________________________________________________
conv1d_transpose_2 (Conv1DTr (None, 128, 1)            449       
_________________________________________________________________
cropping1d (Cropping1D)      (None, 127, 1)            0         
=================================================================
Total params: 36,929
Trainable params: 36,929
Non-trainable params: 0
_________________________________________________________________
(79, 127, 1)
Epoch 1/100
starting readin
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
(80, 127, 1)
Normalizing training data
(79, 127, 1)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 64, 64)            512       
_________________________________________________________________
dropout (Dropout)            (None, 64, 64)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 32, 32)            14368     
_________________________________________________________________
conv1d_transpose (Conv1DTran (None, 64, 32)            7200      
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 32)            0         
_________________________________________________________________
conv1d_transpose_1 (Conv1DTr (None, 128, 64)           14400     
_________________________________________________________________
conv1d_transpose_2 (Conv1DTr (None, 128, 1)            449       
_________________________________________________________________
cropping1d (Cropping1D)      (None, 127, 1)            0         
=================================================================
Total params: 36,929
Trainable params: 36,929
Non-trainable params: 0
_________________________________________________________________
(79, 127, 1)
Epoch 1/100
1/1 [==============================] - ETA: 0s - loss: 0.99581/1 [==============================] - 3s 3s/step - loss: 0.9958 - val_loss: 0.6925
1/1 [==============================] - ETA: 0s - loss: 1.00181/1 [==============================] - 3s 3s/step - loss: 1.0018 - val_loss: 0.7778
Epoch 2/100
Epoch 2/100
1/1 [==============================] - ETA: 0s - loss: 0.70761/1 [==============================] - 0s 38ms/step - loss: 0.7076 - val_loss: 1.0976
1/1 [==============================] - ETA: 0s - loss: 0.78221/1 [==============================] - 0s 39ms/step - loss: 0.7822 - val_loss: 1.0778
Epoch 3/100
Epoch 3/100
1/1 [==============================] - ETA: 0s - loss: 1.09151/1 [==============================] - 0s 37ms/step - loss: 1.0915 - val_loss: 0.7874
1/1 [==============================] - ETA: 0s - loss: 1.09801/1 [==============================] - 0s 36ms/step - loss: 1.0980 - val_loss: 2.4581
Epoch 4/100
Epoch 4/100
1/1 [==============================] - ETA: 0s - loss: 0.78641/1 [==============================] - 0s 36ms/step - loss: 0.7864 - val_loss: 0.5522
1/1 [==============================] - ETA: 0s - loss: 2.46331/1 [==============================] - 0s 37ms/step - loss: 2.4633 - val_loss: 0.4627
Epoch 5/100
Epoch 5/100
1/1 [==============================] - ETA: 0s - loss: 0.55591/1 [==============================] - 0s 35ms/step - loss: 0.5559 - val_loss: 1.0838
1/1 [==============================] - ETA: 0s - loss: 0.47161/1 [==============================] - 0s 36ms/step - loss: 0.4716 - val_loss: 0.6737
Epoch 6/100
Epoch 6/100
1/1 [==============================] - ETA: 0s - loss: 1.08601/1 [==============================] - 0s 36ms/step - loss: 1.0860 - val_loss: 0.3396
1/1 [==============================] - ETA: 0s - loss: 0.66851/1 [==============================] - 0s 37ms/step - loss: 0.6685 - val_loss: 0.8338
Epoch 7/100
Epoch 7/100
1/1 [==============================] - ETA: 0s - loss: 0.34741/1 [==============================] - 0s 35ms/step - loss: 0.3474 - val_loss: 0.3202
1/1 [==============================] - ETA: 0s - loss: 0.83121/1 [==============================] - 0s 36ms/step - loss: 0.8312 - val_loss: 0.8977
Epoch 8/100
Epoch 8/100
1/1 [==============================] - ETA: 0s - loss: 0.32631/1 [==============================] - 0s 36ms/step - loss: 0.3263 - val_loss: 0.5301
1/1 [==============================] - ETA: 0s - loss: 0.89431/1 [==============================] - 0s 37ms/step - loss: 0.8943 - val_loss: 0.9184
Epoch 9/100
Epoch 9/100
1/1 [==============================] - ETA: 0s - loss: 0.55771/1 [==============================] - 0s 35ms/step - loss: 0.5577 - val_loss: 0.4688
1/1 [==============================] - ETA: 0s - loss: 0.91581/1 [==============================] - 0s 36ms/step - loss: 0.9158 - val_loss: 0.9185
Epoch 10/100
Epoch 10/100
1/1 [==============================] - ETA: 0s - loss: 0.49121/1 [==============================] - 0s 35ms/step - loss: 0.4912 - val_loss: 0.4418
1/1 [==============================] - ETA: 0s - loss: 0.91541/1 [==============================] - 0s 37ms/step - loss: 0.9154 - val_loss: 0.9019
Epoch 11/100
Epoch 11/100
1/1 [==============================] - ETA: 0s - loss: 0.44731/1 [==============================] - 0s 36ms/step - loss: 0.4473 - val_loss: 0.4902
1/1 [==============================] - ETA: 0s - loss: 0.89961/1 [==============================] - 0s 36ms/step - loss: 0.8996 - val_loss: 0.8637
Epoch 12/100
Epoch 12/100
1/1 [==============================] - ETA: 0s - loss: 0.49091/1 [==============================] - 0s 36ms/step - loss: 0.4909 - val_loss: 0.4986
1/1 [==============================] - ETA: 0s - loss: 0.86121/1 [==============================] - 0s 37ms/step - loss: 0.8612 - val_loss: 0.7922
Epoch 13/100
Epoch 13/100
1/1 [==============================] - ETA: 0s - loss: 0.49931/1 [==============================] - 0s 36ms/step - loss: 0.4993 - val_loss: 0.4463
1/1 [==============================] - ETA: 0s - loss: 0.78911/1 [==============================] - 0s 36ms/step - loss: 0.7891 - val_loss: 0.6717
Epoch 14/100
Epoch 14/100
1/1 [==============================] - ETA: 0s - loss: 0.44581/1 [==============================] - 0s 36ms/step - loss: 0.4458 - val_loss: 0.3463
1/1 [==============================] - ETA: 0s - loss: 0.66841/1 [==============================] - 0s 36ms/step - loss: 0.6684 - val_loss: 0.5096
Epoch 15/100
1/1 [==============================] - ETA: 0s - loss: 0.35241/1 [==============================] - 0s 35ms/step - loss: 0.3524 - val_loss: 0.2508
Epoch 16/100
1/1 [==============================] - ETA: 0s - loss: 0.25981/1 [==============================] - 0s 37ms/step - loss: 0.2598 - val_loss: 0.1919
Epoch 17/100
1/1 [==============================] - ETA: 0s - loss: 0.21681/1 [==============================] - 0s 36ms/step - loss: 0.2168 - val_loss: 0.0779
Epoch 18/100
1/1 [==============================] - ETA: 0s - loss: 0.09771/1 [==============================] - 0s 36ms/step - loss: 0.0977 - val_loss: 0.1516
Epoch 19/100
1/1 [==============================] - ETA: 0s - loss: 0.16461/1 [==============================] - 0s 35ms/step - loss: 0.1646 - val_loss: 0.2196
Epoch 20/100
1/1 [==============================] - ETA: 0s - loss: 0.23411/1 [==============================] - 0s 35ms/step - loss: 0.2341 - val_loss: 0.1273
Epoch 21/100
1/1 [==============================] - ETA: 0s - loss: 0.14141/1 [==============================] - 0s 35ms/step - loss: 0.1414 - val_loss: 0.0615
Epoch 22/100
1/1 [==============================] - ETA: 0s - loss: 0.07491/1 [==============================] - 0s 35ms/step - loss: 0.0749 - val_loss: 0.0691
Epoch 23/100
1/1 [==============================] - ETA: 0s - loss: 0.08371/1 [==============================] - 0s 34ms/step - loss: 0.0837 - val_loss: 0.1042
Epoch 24/100
1/1 [==============================] - ETA: 0s - loss: 0.12531/1 [==============================] - 0s 35ms/step - loss: 0.1253 - val_loss: 0.1010
Epoch 25/100
1/1 [==============================] - ETA: 0s - loss: 0.12041/1 [==============================] - 0s 34ms/step - loss: 0.1204 - val_loss: 0.0818
Epoch 26/100
1/1 [==============================] - ETA: 0s - loss: 0.09341/1 [==============================] - 0s 34ms/step - loss: 0.0934 - val_loss: 0.0772
Epoch 27/100
1/1 [==============================] - ETA: 0s - loss: 0.08611/1 [==============================] - 0s 34ms/step - loss: 0.0861 - val_loss: 0.0602
Epoch 28/100
1/1 [==============================] - ETA: 0s - loss: 0.06501/1 [==============================] - 0s 35ms/step - loss: 0.0650 - val_loss: 0.0303
Epoch 29/100
1/1 [==============================] - ETA: 0s - loss: 0.04101/1 [==============================] - 0s 34ms/step - loss: 0.0410 - val_loss: 0.0151
Epoch 30/100
1/1 [==============================] - ETA: 0s - loss: 0.03411/1 [==============================] - 0s 35ms/step - loss: 0.0341 - val_loss: 0.0331
Epoch 31/100
1/1 [==============================] - ETA: 0s - loss: 0.06061/1 [==============================] - 0s 34ms/step - loss: 0.0606 - val_loss: 0.0347
Epoch 32/100
1/1 [==============================] - ETA: 0s - loss: 0.06231/1 [==============================] - 0s 34ms/step - loss: 0.0623 - val_loss: 0.0139
Epoch 33/100
1/1 [==============================] - ETA: 0s - loss: 0.03621/1 [==============================] - 0s 34ms/step - loss: 0.0362 - val_loss: 0.0162
Epoch 34/100
1/1 [==============================] - ETA: 0s - loss: 0.02961/1 [==============================] - 0s 34ms/step - loss: 0.0296 - val_loss: 0.0324
Epoch 35/100
1/1 [==============================] - ETA: 0s - loss: 0.04181/1 [==============================] - 0s 34ms/step - loss: 0.0418 - val_loss: 0.0296
Epoch 36/100
1/1 [==============================] - ETA: 0s - loss: 0.04261/1 [==============================] - 0s 35ms/step - loss: 0.0426 - val_loss: 0.0147
Epoch 37/100
1/1 [==============================] - ETA: 0s - loss: 0.03111/1 [==============================] - 0s 35ms/step - loss: 0.0311 - val_loss: 0.0067
Epoch 38/100
1/1 [==============================] - ETA: 0s - loss: 0.02561/1 [==============================] - 0s 34ms/step - loss: 0.0256 - val_loss: 0.0043
Epoch 39/100
1/1 [==============================] - ETA: 0s - loss: 0.02551/1 [==============================] - 0s 34ms/step - loss: 0.0255 - val_loss: 0.0055
Epoch 40/100
1/1 [==============================] - ETA: 0s - loss: 0.02251/1 [==============================] - 0s 34ms/step - loss: 0.0225 - val_loss: 0.0098
Epoch 41/100
1/1 [==============================] - ETA: 0s - loss: 0.02481/1 [==============================] - 0s 34ms/step - loss: 0.0248 - val_loss: 0.0106
Epoch 42/100
1/1 [==============================] - ETA: 0s - loss: 0.02381/1 [==============================] - 0s 35ms/step - loss: 0.0238 - val_loss: 0.0071
Epoch 43/100
1/1 [==============================] - ETA: 0s - loss: 0.02141/1 [==============================] - 0s 34ms/step - loss: 0.0214 - val_loss: 0.0044
Epoch 44/100
1/1 [==============================] - ETA: 0s - loss: 0.01871/1 [==============================] - 0s 34ms/step - loss: 0.0187 - val_loss: 0.0063
Epoch 45/100
1/1 [==============================] - ETA: 0s - loss: 0.02221/1 [==============================] - 0s 34ms/step - loss: 0.0222 - val_loss: 0.0072
Epoch 46/100
1/1 [==============================] - ETA: 0s - loss: 0.02021/1 [==============================] - 0s 53ms/step - loss: 0.0202 - val_loss: 0.0072
Epoch 47/100
1/1 [==============================] - ETA: 0s - loss: 0.01981/1 [==============================] - 0s 35ms/step - loss: 0.0198 - val_loss: 0.0072
Epoch 48/100
1/1 [==============================] - ETA: 0s - loss: 0.01931/1 [==============================] - 0s 34ms/step - loss: 0.0193 - val_loss: 0.0056
(127, 1)
(127, 1)
(1, 127, 1)
54
(1, 127, 1)
(127, 1)
(127, 1)
(1, 127, 1)
49
(1, 127, 1)
